{"cells":[{"cell_type":"code","execution_count":null,"id":"735714e2","metadata":{"id":"735714e2"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from keras.models import Sequential\n","from keras.layers import Dense\n","import pickle\n","\n","# Load and preprocess data\n","ipl = pd.read_csv(\"ipl_data.csv\")\n","df = ipl[[\"bat_team\", \"bowl_team\", \"overs\", \"runs\", \"wickets\", \"total\"]].copy()\n","df.columns = [\"batting_team\", \"bowling_team\", \"overs\", \"runs\", \"wickets\", \"total\"]\n","\n","# Label encode teams\n","label_encoders = {}\n","for col in [\"batting_team\", \"bowling_team\"]:\n","    le = LabelEncoder()\n","    df[col] = le.fit_transform(df[col])\n","    label_encoders[col] = le\n","\n","# Define features and target\n","X = df.drop(\"total\", axis=1)\n","y = df[\"total\"]\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Scale features\n","scaler = MinMaxScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"id":"10f364f5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10f364f5","executionInfo":{"status":"ok","timestamp":1744703073728,"user_tz":-330,"elapsed":478659,"user":{"displayName":"22 573 LE DOKI VENKATESWARARAO","userId":"09022131001755595180"}},"outputId":"ffd4a2da-be10-4f1b-dc17-390ffd22097d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 8622.7490 - val_loss: 491.9240\n","Epoch 2/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 478.2940 - val_loss: 446.0857\n","Epoch 3/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 449.4968 - val_loss: 424.6529\n","Epoch 4/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 436.7795 - val_loss: 421.5957\n","Epoch 5/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 432.4690 - val_loss: 426.9584\n","Epoch 6/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 427.5837 - val_loss: 417.7067\n","Epoch 7/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 428.9529 - val_loss: 419.2739\n","Epoch 8/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 423.7119 - val_loss: 415.2367\n","Epoch 9/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 428.6613 - val_loss: 413.6616\n","Epoch 10/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 428.3804 - val_loss: 415.1531\n","Epoch 11/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 424.9908 - val_loss: 418.9640\n","Epoch 12/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 425.9948 - val_loss: 414.3720\n","Epoch 13/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 416.4702 - val_loss: 410.4846\n","Epoch 14/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 427.3544 - val_loss: 408.7213\n","Epoch 15/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 416.5602 - val_loss: 407.5865\n","Epoch 16/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 416.2751 - val_loss: 407.4901\n","Epoch 17/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 419.1393 - val_loss: 405.2107\n","Epoch 18/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 417.0855 - val_loss: 405.2682\n","Epoch 19/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 412.9492 - val_loss: 403.1207\n","Epoch 20/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 413.7076 - val_loss: 401.9421\n","Epoch 21/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 417.5878 - val_loss: 403.9020\n","Epoch 22/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 409.8828 - val_loss: 399.4662\n","Epoch 23/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 414.7186 - val_loss: 400.8424\n","Epoch 24/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 418.0690 - val_loss: 401.6946\n","Epoch 25/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 417.4593 - val_loss: 400.3942\n","Epoch 26/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 409.7670 - val_loss: 401.2687\n","Epoch 27/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 406.3116 - val_loss: 412.4474\n","Epoch 28/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 410.8542 - val_loss: 398.5638\n","Epoch 29/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 408.1847 - val_loss: 401.7838\n","Epoch 30/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 411.8368 - val_loss: 401.1291\n","Epoch 31/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 406.5019 - val_loss: 399.5930\n","Epoch 32/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 414.0242 - val_loss: 398.9697\n","Epoch 33/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 402.5126 - val_loss: 399.5639\n","Epoch 34/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 411.0787 - val_loss: 400.8022\n","Epoch 35/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 412.6708 - val_loss: 399.8983\n","Epoch 36/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 412.0511 - val_loss: 398.6477\n","Epoch 37/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 411.9409 - val_loss: 399.7397\n","Epoch 38/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 407.7476 - val_loss: 398.6323\n","Epoch 39/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 407.9946 - val_loss: 405.1783\n","Epoch 40/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 410.4685 - val_loss: 397.9795\n","Epoch 41/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 409.2532 - val_loss: 408.1893\n","Epoch 42/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 413.3636 - val_loss: 397.7463\n","Epoch 43/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 409.2407 - val_loss: 399.6785\n","Epoch 44/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 412.0958 - val_loss: 399.0283\n","Epoch 45/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 414.4687 - val_loss: 397.6854\n","Epoch 46/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 404.8594 - val_loss: 400.5824\n","Epoch 47/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 414.5699 - val_loss: 411.2437\n","Epoch 48/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 408.6388 - val_loss: 399.9250\n","Epoch 49/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 410.3740 - val_loss: 397.0127\n","Epoch 50/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 411.5632 - val_loss: 397.5617\n","Epoch 51/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 411.4760 - val_loss: 396.5403\n","Epoch 52/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 413.1108 - val_loss: 396.7565\n","Epoch 53/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 408.0930 - val_loss: 416.3501\n","Epoch 54/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 405.0012 - val_loss: 397.6512\n","Epoch 55/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 406.1488 - val_loss: 397.0068\n","Epoch 56/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 405.9349 - val_loss: 398.7434\n","Epoch 57/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 418.6613 - val_loss: 406.2940\n","Epoch 58/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 409.0818 - val_loss: 397.6044\n","Epoch 59/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 411.6391 - val_loss: 396.4546\n","Epoch 60/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 408.1653 - val_loss: 395.6079\n","Epoch 61/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 408.4129 - val_loss: 395.0357\n","Epoch 62/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 407.9838 - val_loss: 396.2138\n","Epoch 63/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 401.2131 - val_loss: 394.9384\n","Epoch 64/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 407.3610 - val_loss: 396.2043\n","Epoch 65/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 411.3410 - val_loss: 394.0752\n","Epoch 66/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 404.6884 - val_loss: 394.0645\n","Epoch 67/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 415.6498 - val_loss: 394.0142\n","Epoch 68/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 408.7359 - val_loss: 399.5964\n","Epoch 69/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 402.6473 - val_loss: 396.6740\n","Epoch 70/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 409.8468 - val_loss: 395.6970\n","Epoch 71/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 405.4356 - val_loss: 396.9405\n","Epoch 72/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 407.2816 - val_loss: 393.7350\n","Epoch 73/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 409.1045 - val_loss: 394.2587\n","Epoch 74/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 409.3886 - val_loss: 393.3814\n","Epoch 75/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 404.3581 - val_loss: 393.3007\n","Epoch 76/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 403.1838 - val_loss: 394.4366\n","Epoch 77/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 398.2626 - val_loss: 392.7531\n","Epoch 78/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 397.7680 - val_loss: 392.4034\n","Epoch 79/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 407.1969 - val_loss: 405.0942\n","Epoch 80/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 405.0680 - val_loss: 393.4305\n","Epoch 81/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 407.7959 - val_loss: 394.3016\n","Epoch 82/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 405.6007 - val_loss: 392.8393\n","Epoch 83/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 405.3510 - val_loss: 393.2533\n","Epoch 84/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 408.4968 - val_loss: 394.1402\n","Epoch 85/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 402.6897 - val_loss: 393.9859\n","Epoch 86/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 406.3924 - val_loss: 398.5462\n","Epoch 87/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 405.1678 - val_loss: 395.4938\n","Epoch 88/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 398.4615 - val_loss: 393.5087\n","Epoch 89/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 402.9789 - val_loss: 391.7650\n","Epoch 90/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 403.8680 - val_loss: 392.2520\n","Epoch 91/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 404.2243 - val_loss: 392.8182\n","Epoch 92/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 405.4065 - val_loss: 391.4957\n","Epoch 93/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 404.6837 - val_loss: 392.9339\n","Epoch 94/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 402.5012 - val_loss: 395.1125\n","Epoch 95/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 395.4127 - val_loss: 391.3848\n","Epoch 96/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 407.4159 - val_loss: 393.8481\n","Epoch 97/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 409.1803 - val_loss: 391.5097\n","Epoch 98/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 403.4095 - val_loss: 395.4863\n","Epoch 99/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 406.1833 - val_loss: 391.4708\n","Epoch 100/100\n","\u001b[1m1521/1521\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 408.0591 - val_loss: 392.5596\n","\u001b[1m1901/1901\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n","[[152.84213]\n"," [167.36002]\n"," [151.07611]\n"," ...\n"," [170.2752 ]\n"," [162.86028]\n"," [164.02347]]\n"]}],"source":["# Define and train the MLP model\n","model = Sequential([\n","    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n","    Dense(64, activation='relu'),\n","    Dense(1, activation='linear')\n","])\n","model.compile(optimizer='adam', loss='mse')\n","model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2, verbose=1)\n","print(model.predict(X_train_scaled))\n"]},{"cell_type":"code","execution_count":null,"id":"f86cd6f2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f86cd6f2","executionInfo":{"status":"ok","timestamp":1744703102284,"user_tz":-330,"elapsed":7,"user":{"displayName":"22 573 LE DOKI VENKATESWARARAO","userId":"09022131001755595180"}},"outputId":"14b60dcb-38fc-4c80-eb4e-da4d75b09551"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["Model and preprocessors saved!\n"]}],"source":["# Save model and preprocessors\n","model.save(\"ipl_mlp_model.h5\")\n","with open(\"label_encoders.pkl\", \"wb\") as f:\n","    pickle.dump(label_encoders, f)\n","with open(\"scaler.pkl\", \"wb\") as f:\n","    pickle.dump(scaler, f)\n","\n","print(\"Model and preprocessors saved!\")\n"]}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}